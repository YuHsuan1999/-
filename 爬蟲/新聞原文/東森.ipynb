{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('Bert_EDModel': conda)"
  },
  "interpreter": {
   "hash": "3c7a819655e9f6c16ec335f8a3abf936bf261f9d6cb538ae0c27bb7ccda00602"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import mysql\r\n",
    "from mysql import connect_mysql\r\n",
    "\r\n",
    "conn = connect_mysql()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import requests\r\n",
    "from bs4 import BeautifulSoup as bs\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "href = \"https://news.ebc.net.tw/news/\"\r\n",
    "number = {'world': 'world', 'politics': 'politics', 'society': 'society'}\r\n",
    "\r\n",
    "for i in number.keys():\r\n",
    "  r = requests.get(href + i)\r\n",
    "  soup = bs(r.text, \"lxml\")\r\n",
    "  a = soup.find(\"div\", {\"class\": \"style1 white-box\"})\r\n",
    "  print(a)\r\n",
    "  for temp in (a.findAll(\"div\", {'class': 'style1'})):\r\n",
    "    title_temp = temp.find('a', {'onclick': 'Read(this,\\'rade\\');'})\r\n",
    "    #print(title_temp.text)\r\n",
    "    if(title_temp == None):\r\n",
    "      continue\r\n",
    "\r\n",
    "    #初始化\r\n",
    "    content = ''\r\n",
    "    title = title_temp['title']\r\n",
    "    print(title)\r\n",
    "\r\n",
    "    content_url = 'https://news.ebc.net.tw/' + title_temp['href']\r\n",
    "    print(content_url)\r\n",
    "\r\n",
    "    news_id = content_url.split('/')[-1]\r\n",
    "    print(news_id)\r\n",
    "\r\n",
    "    # 抓取內容\r\n",
    "    r2 = requests.get(content_url)\r\n",
    "    soup2 = bs(r2.text, \"lxml\")\r\n",
    "    a2 = soup2.find(\"div\", {\"class\": \"raw-style\"})\r\n",
    "    # 日期\r\n",
    "    date = soup2.find(\"div\", {\"class\": \"info\"})\r\n",
    "    date = date.find('span', {'class': 'small-gray-text'})\r\n",
    "    date = date.text.split('東森新聞')[0]\r\n",
    "    print(date)\r\n",
    "\r\n",
    "\r\n",
    "    for content_temp in (a2.findAll(\"p\")):\r\n",
    "      if(('▼' in content_temp.text) or ('●' in content_temp.text) or ('封面圖' in content_temp.text) or ('★' in content_temp.text)):     #跳過圖片註解\r\n",
    "        continue\r\n",
    "      \r\n",
    "      if(('延伸閱讀' in content_temp.text)):\r\n",
    "        break\r\n",
    "      \r\n",
    "      if(('訂閱【東森新聞】' in content_temp.text)):\r\n",
    "        content += content_temp.text.split('訂閱【東森新聞】')[0]\r\n",
    "      else:\r\n",
    "        content += content_temp.text\r\n",
    "\r\n",
    "    print(content)\r\n",
    "    \r\n",
    "    # # 確認是否已在DB中\r\n",
    "    # check = 0\r\n",
    "    # with conn.cursor() as cursor:\r\n",
    "    #   sql = 'SELECT News_id FROM original WHERE News_id = %s AND Provenance = \\'東森\\''\r\n",
    "    #   cursor.execute(sql, (news_id))\r\n",
    "    #   result = cursor.fetchall()\r\n",
    "    #   check = None\r\n",
    "    #   for row in result:\r\n",
    "    #     check = row[0]\r\n",
    "\r\n",
    "    # # 若已在DB中則跳過\r\n",
    "    # if(str(check) == news_id):\r\n",
    "    #   continue\r\n",
    "    # with conn.cursor() as cursor:\r\n",
    "    #     # 新增資料SQL語法\r\n",
    "    #     command = 'INSERT INTO original VALUES(%s, %s, %s, %s, %s, %s, %s)'\r\n",
    "    #     cursor.execute(command, (news_id, date, title, content_url, number[i], '東森', content))\r\n",
    "    #     # 儲存變更\r\n",
    "    # conn.commit()\r\n",
    "    print('--------------')\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
      "<html><head><meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "<title>ERROR: The request could not be satisfied</title>\n",
      "</head><body>\n",
      "<h1>403 ERROR</h1>\n",
      "<h2>The request could not be satisfied.</h2>\n",
      "<hr noshade=\"\" size=\"1px\"/>\n",
      "Request blocked.\n",
      "We can't connect to the server for this app or website at this time. There might be too much traffic or a configuration error. Try again later, or contact the app or website owner.\n",
      "<br clear=\"all\"/>\n",
      "If you provide content to customers through CloudFront, you can find steps to troubleshoot and help prevent this error by reviewing the CloudFront documentation.\n",
      "<br clear=\"all\"/>\n",
      "<hr noshade=\"\" size=\"1px\"/>\n",
      "<pre>\n",
      "Generated by cloudfront (CloudFront)\n",
      "Request ID: _T2P9_saJlOOC9yRTt7xyn9jNzmjGTvPHv29jSlIQa_HkEY-l921ow==\n",
      "</pre>\n",
      "<address>\n",
      "</address>\n",
      "</body></html>\n",
      "None\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'findAll'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-76c601e51be8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"style1 white-box\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m   \u001b[1;32mfor\u001b[0m \u001b[0mtemp\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'style1'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mtitle_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'onclick'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Read(this,\\'rade\\');'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#print(title_temp.text)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'findAll'"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}